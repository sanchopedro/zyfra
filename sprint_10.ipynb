{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Zyfra – Modelo de Previsão para Extração de Ouro\n",
    "\n",
    "É hora de lidar com um problema real de ciência de dados do campo da mineração de ouro. Este projeto foi fornecido pela Zyfra (os materiais estão em inglês).\n",
    "\n",
    "## Descrição da Tarefa\n",
    "\n",
    "Prepare um protótipo de um modelo de aprendizado de máquina para o Zyfra. A empresa desenvolve soluções de eficiência para a indústria pesada.\n",
    "\n",
    "O modelo deve prever a quantidade de ouro puro extraído do minério de ouro. Você tem os dados sobre a extração e a purificação.\n",
    "\n",
    "## Descrição do Projeto\n",
    "\n",
    "Os dados são indexados com a data e hora da aquisição (característica data). Os parâmetros que estão próximos uns dos outros em termos de tempo geralmente são semelhantes.\n",
    "\n",
    "Alguns parâmetros não estão disponíveis porque foram medidos e/ou calculados muito mais tarde. Por isso, algumas das características presentes no conjunto de treinamento podem estar ausentes do conjunto de teste. O conjunto de teste também não contém objetivos.\n",
    "\n",
    "O conjunto de dados de origem contém os conjuntos de treinamento e teste com todas as características.\n",
    "\n",
    "Você tem os dados brutos, recebidos diretamente do cliente. Antes de construir o modelo, verifique a exatidão dos dados. Para isso, use nossas instruções.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PREPARAÇÃO DOS DADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configurando o Pandas a mostrar o máximo de colunas e linhas\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Impedir avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Criação gráfica\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Modelo\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, make_scorer\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Column Transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Pre processamento\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue os arquivos de dados em diferentes DataFrames\n",
    "\n",
    "# Local Path\n",
    "local_gold_recov_full_path = \"gold_recovery_full.csv\"\n",
    "local_gold_recov_test_path = \"gold_recovery_test.csv\"\n",
    "local_gold_recov_train_path = \"gold_recovery_train.csv\"\n",
    "\n",
    "# Cloud Path\n",
    "gold_recov_full_path = \"/datasets/gold_recovery_full.csv\"\n",
    "gold_recov_test_path = \"/datasets/gold_recovery_test.csv\"\n",
    "gold_recov_train_path = \"/datasets/gold_recovery_train.csv\"\n",
    "\n",
    "try:\n",
    "    df_full = pd.read_csv(local_gold_recov_full_path, sep=\",\", parse_dates=True)\n",
    "    df_test = pd.read_csv(local_gold_recov_test_path, sep=\",\", parse_dates=True)\n",
    "    df_train = pd.read_csv(local_gold_recov_train_path, sep=\",\", parse_dates=True)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        f\"O arquivo CSV não foi encontrado em {local_gold_recov_full_path}. Tentando o caminho {gold_recov_full_path}...\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"O arquivo CSV não foi encontrado em {local_gold_recov_test_path}. Tentando o caminho {gold_recov_test_path}...\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"O arquivo CSV não foi encontrado em {local_gold_recov_train_path}. Tentando o caminho {gold_recov_train_path}...\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        df_full = pd.read_csv(gold_recov_full_path, sep=\",\", parse_dates=True)\n",
    "        df_test = pd.read_csv(gold_recov_test_path, sep=\",\", parse_dates=True)\n",
    "        df_train = pd.read_csv(gold_recov_train_path, sep=\",\", parse_dates=True)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\n",
    "            f\"O arquivo CSV não foi encontrado em {gold_recov_full_path}. Nenhum arquivo encontrado.\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"O arquivo CSV não foi encontrado em {gold_recov_test_path}. Nenhum arquivo encontrado.\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"O arquivo CSV não foi encontrado em {gold_recov_train_path}. Nenhum arquivo encontrado.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando o shape dos dataframes\n",
    "\n",
    "df_full.shape, df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber de cara, que há uma diferença de colunas usadas entre o dataset de treino (87) e o dataset de teste (53)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando se DataFrame foi importado\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando se DataFrame foi importado\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando se DataFrame foi importado\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Checando se a quantidade retirada foi calculada corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiando o dataframe de treinamento\n",
    "new_df = df_train.copy()\n",
    "\n",
    "# Separando as colunas necessárias para análise\n",
    "subset_columns = subset = [\n",
    "    \"rougher.output.recovery\",\n",
    "    \"rougher.output.concentrate_au\",\n",
    "    \"rougher.input.feed_au\",\n",
    "    \"rougher.output.tail_au\",\n",
    "]\n",
    "\n",
    "# Crie um novo DataFrame com o subset das colunas necessárias\n",
    "df_train_recovery_calc_subset = new_df[subset_columns]\n",
    "df_train_recovery_calc_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_recovery_calc_subset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos dados faltantes, como podemos ver a abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_recovery_calc_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer o drop desses dados faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropna\n",
    "df_train_recovery_calc_subset = df_train_recovery_calc_subset.dropna()\n",
    "\n",
    "# Checando se os dados foram apagados\n",
    "df_train_recovery_calc_subset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as linhas de dados faltantes apagados, podemos calcular o valor de recovery, de acordo com a fórmula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a recuperação de ouro\n",
    "def calculate_recovery(df, C, F, T):\n",
    "    \"\"\"\n",
    "    Função para calcular a recuperação de ouro.\n",
    "\n",
    "    Para calcular rougher recovery, a função precisa dos seguintes imputs:\n",
    "    - df = DataFrame onde a coluna está presente\n",
    "    - C = proporção de ouro no concentrado logo após a flotação\n",
    "    - F = a proporção de ouro alimentado no sistema antes da flotação\n",
    "    - T = a proporção de ouro nos restos de minério bruto logo após a flotação\n",
    "\n",
    "    Esta função retorna o percentual de recuperação do concentrado de ouro após a etapa de purificação.\n",
    "    \"\"\"\n",
    "\n",
    "    recovery = (df[C] * (df[F] - df[T])) / (df[F] * (df[C] - df[T])) * 100\n",
    "\n",
    "    return recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculando o valor de recovery\n",
    "calculated_recovery = calculate_recovery(\n",
    "    df_train_recovery_calc_subset,\n",
    "    \"rougher.output.concentrate_au\",\n",
    "    \"rougher.input.feed_au\",\n",
    "    \"rougher.output.tail_au\",\n",
    ")\n",
    "# Mostrando o resultado das 10 primeiras amostras\n",
    "calculated_recovery.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos calcular o Mean Absolute Error (MAE) entre o cálculo gravado em calculated_recovery e os valores da feature df_train_recovery_calc_subset['rougher.output.recovery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo Mean Absolute Error\n",
    "mae = mean_absolute_error(\n",
    "    df_train_recovery_calc_subset[\"rougher.output.recovery\"], calculated_recovery\n",
    ")\n",
    "\n",
    "print(f\"A diferença entre os cálculos e o valores originais são de: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O fato de o erro médio absoluto (MAE) entre nossos valores de recuperação calculados e os valores de recurso fornecidos, ser de 9.303415616264301e-15, ou seja, quase zero, sugere que nossos cálculos são quase idêntico aos valores de recurso fornecidos para rougher.output.recovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Analisando recursos que não estão disponíveis no conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Olhando as colunas que não foram usadas no dataframe de teste\n",
    "missed_columns = list(set(df_train.columns) - set(df_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente, todos os recursos que não estão incluídos no conjunto de teste são do tipo \"_output_\" e \"calculation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho das colunas faltantes\n",
    "len(missed_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "São 34 colunas faltantes nop conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[missed_columns].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que todas as colunas faltantes são do tipo float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Preparação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Checando dados faltosos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_values_report(dataset_name: str, df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Esta função:\n",
    "     1. Primeiro, usa um DataFrame como entrada.\n",
    "     2. calcula as informações de valor ausentes e cria um relatório.\n",
    "     3. imprime as informações e o relatório.\n",
    "    \"\"\"\n",
    "    # Calcula o número de valores faltantes em todas as colunas do DataFrame\n",
    "    number_missing_values = df.isna().sum()\n",
    "\n",
    "    # Obtém o número total de registros/observações no DataFrame\n",
    "    number_of_rows = df.shape[0]\n",
    "\n",
    "    # Calcula a porcentagem de valores faltantes em todas as colunas do DataFrame\n",
    "    percentage_of_missing_values = round(\n",
    "        (number_missing_values / number_of_rows) * 100, 2\n",
    "    )\n",
    "\n",
    "    # Crie um novo DataFrame com número de valores ausentes e porcentagem de valores ausentes em todas as colunas\n",
    "    df_missing_values = pd.concat(\n",
    "        [number_missing_values, percentage_of_missing_values], axis=1\n",
    "    )\n",
    "    df_missing_values = df_missing_values.rename(\n",
    "        columns={0: \"No of Missing Values\", 1: \"Percentage of Missing Values\"}\n",
    "    )\n",
    "\n",
    "    # Classifica o novo DataFrame de acordo com a porcentagem de valores ausentes em ordem decrescente\n",
    "    df_missing_values = df_missing_values.sort_values(\n",
    "        by=\"Percentage of Missing Values\", ascending=False\n",
    "    )\n",
    "\n",
    "    # Imprime as estatísticas de valor faltantes\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(f\"        {dataset_name} Missing Values Report\")\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(f\"Total number of rows: {number_of_rows}\")\n",
    "    print(f\"Total number of columns: {df.shape[1]}\")\n",
    "    print()\n",
    "    print(\"Informações sobre o número e porcentagem de valores ausentes no DataFrame\")\n",
    "    display(df_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the DataFrames\n",
    "list_of_df = [\n",
    "    {\"name\": \"Training Dataset\", \"data\": df_train},\n",
    "    {\"name\": \"Test Dataset\", \"data\": df_test},\n",
    "    {\"name\": \"Source Dataset\", \"data\": df_full},\n",
    "]\n",
    "for item in list_of_df:\n",
    "    get_missing_values_report(item[\"name\"], item[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que em todos os datasets, temos dados faltantes. Apenas as colunas [\"primary_cleaner.input.feed_size\", \"date\"] que possuem todos os dados. \n",
    "\n",
    "- Como na descrição do projeto fala: \n",
    "  \n",
    "      Os dados são indexados com a data e hora da aquisição (característica data). Os parâmetros que estão próximos uns dos outros em termos de tempo geralmente são semelhantes.\n",
    "\n",
    "Logo, podemos preencher os dados ausentes com os valores próximos, porém, não pode ser feito para as variáveis objetivos.\n",
    "\n",
    "Vamos corrigir as colunas que possuem dados faltantes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para preencher os valores ausentes no DataFrame\n",
    "\n",
    "target_cols = [\"rougher.output.recovery\", \"final.output.recovery\"]\n",
    "\n",
    "\n",
    "def forward_fill_missing_values(df: pd.DataFrame):\n",
    "    for col in df:\n",
    "        if col not in target_cols:\n",
    "            df[col].fillna(method=\"ffill\", axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher os valores faltantes\n",
    "forward_fill_missing_values(df_train)\n",
    "forward_fill_missing_values(df_test)\n",
    "forward_fill_missing_values(df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como não foi preenchido os valores ausentes para as colunas objetivos, vamos eliminar as linhas dessas colunas que têm valores ausentes, para poder estimar os modelos de ML mais pra frente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dos valores ausentes no df_train\n",
    "df_train = df_train.dropna(subset=[\"final.output.recovery\", \"rougher.output.recovery\"])\n",
    "\n",
    "# Checando se ainda consta algum valor ausente no df_train\n",
    "df_train[[\"final.output.recovery\", \"rougher.output.recovery\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dos valores ausentes no df_full\n",
    "df_full = df_full.dropna(subset=[\"final.output.recovery\", \"rougher.output.recovery\"])\n",
    "\n",
    "# Checando se ainda consta algum valor ausente no df_full\n",
    "df_full[[\"final.output.recovery\", \"rougher.output.recovery\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando de novo os valores nulos\n",
    "for item in list_of_df:\n",
    "    item[\"data\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Checando duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando os dados duplicados no df_train\n",
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando os dados duplicados no df_test\n",
    "df_test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando os dados duplicados no df_full\n",
    "df_full.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não existem dados duplicados em nenhum dos dataframes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Checandos os datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pode ser visto anteriormente, a coluna \"date\" não está como datetime. Vamos alterar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo a coluna datepara datetime\n",
    "df_train[\"date\"] = pd.to_datetime(df_train[\"date\"])\n",
    "\n",
    "# Print info\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo a coluna datepara datetime\n",
    "df_test[\"date\"] = pd.to_datetime(df_test[\"date\"])\n",
    "\n",
    "# Print info\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo a coluna datepara datetime\n",
    "df_full[\"date\"] = pd.to_datetime(df_full[\"date\"])\n",
    "\n",
    "# Print info\n",
    "df_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos os dados limpos, os dados ausentes preenchidos e com os tipos corretos. Podemos prosseguir com as análises dos dados!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ANÁLISE DE DADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Analisando como a concentração de metais (Au, Ag, Pb) muda dependendo do estágio de purificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que temos possíveis 4 valores de estágios: rougher, primary_cleaner, secondary_cleaner e final. Porém dos metais concentrados, no dataframe df_train, não apresenta a variável secondary_cleaner.\n",
    "\n",
    "Dessa forma, analisaremos os 3 estágios: rougher, primary_cleaner e final, juntamente com os dados de input dos metais brutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os estágios\n",
    "stages = [\n",
    "    \"rougher.input.feed\",\n",
    "    \"rougher.output.concentrate\",\n",
    "    \"primary_cleaner.output.concentrate\",\n",
    "    \"final.output.concentrate\",\n",
    "]\n",
    "\n",
    "# Criação de dicionário para cada metal\n",
    "metals = {\"_au\": \"Ouro\", \"_ag\": \"Prata\", \"_pb\": \"Chumbo\"}\n",
    "\n",
    "\n",
    "# Criação subplots para visualizar a concentração de cada metal\n",
    "def plot_metal_concentration(df: pd.DataFrame, df_name: str):\n",
    "    \"\"\"\n",
    "    Essa função:\n",
    "\n",
    "    1. Faz o subplot da quantidade de gráficos que precisaremos, i.e., quantidade de metais da lista.\n",
    "\n",
    "    2. plota o grafico de kernek Density Estimate (KDE) para visualizar a distribuição das observações no dataset, ao longo do histograma, de cada um dos metrais da lista e de cada estágio de purificação.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 14), sharey=False)\n",
    "    fig.suptitle(\n",
    "        f\"Mudança na Concentração de Metal por Estágio de Purificação (Densidade) \\n\\nDataSet: {df_name}\",\n",
    "        fontsize=15,\n",
    "        y=1,\n",
    "    )\n",
    "\n",
    "    for metal in metals.keys():\n",
    "        for stage in stages:\n",
    "            ax = list(metals.keys()).index(metal)\n",
    "            sns.kdeplot(\n",
    "                df[(stage + metal)], ax=axes[ax], shade=\"fill\", label=(stage + metal)\n",
    "            )\n",
    "            axes[ax].legend()\n",
    "            axes[ax].set_xlabel(\n",
    "                \"Concentração de \" + metals[metal] + \" (%)\", fontsize=12, labelpad=10\n",
    "            )\n",
    "            axes[ax].xaxis.set_label_position(\"top\")\n",
    "            axes[ax].set_ylabel(\"Densidade\", fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a distribuição das concentrações de metais (Au, Ag, Pb) para cada estágio de purificação para df_full\n",
    "plot_metal_concentration(df_full, \"df_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar a distribuição das concentrações de metais (Au, Ag, Pb) para cada estágio de purificação para df_train\n",
    "plot_metal_concentration(df_train, \"df_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto no dataset df_full quanto no df_train, as observações são bem próximas, ou seja, a mudança na concentração de metal por estágio de purificação, são bem parecidas. Porém, olhando individualmente cada metal, há diferenças como:\n",
    "\n",
    "- **Ouro**: A cada etapa do processo de purificação, a concentração de ouro aumenta.\n",
    "\n",
    "- **Prata**: Após o processo de \"feed\", a concentração de prata aumenta, mas diminui a cada processo subsequente. O resultado final, \"final.output.concentrate\" é de uma concentração de prata inferior à concentração da mistura inicial do minério.\n",
    "\n",
    "- **Chumbo**: Parece que a concentração de chumbo aumenta até a o segundo estágio do processo de limpeza, \"rougher.output.concentrate\", onde permanece aproximadamente igual à concentração final do processo de limpeza.\n",
    "\n",
    "Podemos observar também, que há outliers nos dados. Pois, para cada etapa do processo, há casos em que a concentração de cada metal é 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Comparando a distribuição do tamanho das partículas do minério no conjunto de treinamento e no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 6))\n",
    "fig.suptitle(\n",
    "    \"Distribuição dos valores Primary Cleaner e Rougher Input Feed_Size (Densidade)\",\n",
    "    fontsize=15,\n",
    "    y=1,\n",
    ")\n",
    "\n",
    "sns.kdeplot(\n",
    "    df_train[\"primary_cleaner.input.feed_size\"],\n",
    "    fill=True,\n",
    "    label=\"Train - Primary Feed Size\",\n",
    ")\n",
    "sns.kdeplot(\n",
    "    df_test[\"primary_cleaner.input.feed_size\"],\n",
    "    fill=True,\n",
    "    label=\"Test - Primary Feed Size\",\n",
    ")\n",
    "sns.kdeplot(\n",
    "    df_train[\"rougher.input.feed_size\"], fill=True, label=\"Train - Rougher Feed Size\"\n",
    ")\n",
    "sns.kdeplot(\n",
    "    df_test[\"rougher.input.feed_size\"], fill=True, label=\"Test - Rougher Feed Size\"\n",
    ")\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel(\"Valores Feed Size\", fontsize=12, labelpad=10)\n",
    "plt.ylabel(\"Densidade\", fontsize=12)\n",
    "plt.xlim(0, 150)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver no gráfico acima, as distribuições de valores para 'primary_cleaner.input.feed_size' e 'rougher.input.feed_size' são aproximadamente as mesmas para os conjuntos de dados de treinamento e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Considerando as concentrações totais de todas as substâncias em diferentes estágios. Há anomalias em ambas amostras?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_and_plot_total_concentrations(\n",
    "    df: pd.DataFrame, stage: str, list_of_columns: list\n",
    "):\n",
    "    \"\"\"\n",
    "    Essa função faz:\n",
    "    1. Calcula o total da concentração de todas as substâncias\n",
    "    2. Plota o histograma\n",
    "    3. Plota o boxplot para analisar os outliers\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculo do total de concentração das substâncias\n",
    "    df[stage] = df[list_of_columns].sum(axis=1)\n",
    "\n",
    "    # Set the plot styles\n",
    "    sns.set(rc={\"figure.figsize\": (16.0, 8.0)})\n",
    "    sns.set(font_scale=1.2)\n",
    "\n",
    "    # Plot histograma\n",
    "    sns.histplot(df[stage], bins=100, stat=\"frequency\", kde=True)\n",
    "    plt.title(\n",
    "        f\"Distribuição Total da Concentração de Todos os Metais no Estágio: {stage}\"\n",
    "    )\n",
    "    plt.xlabel(stage)\n",
    "    plt.show()\n",
    "\n",
    "    # set the boxplot styles\n",
    "    flierprops = dict(\n",
    "        marker=\"o\",\n",
    "        markersize=10,\n",
    "        markeredgecolor=\"black\",\n",
    "        markerfacecolor=\"darkgreen\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    meanprops = dict(marker=\"s\", markerfacecolor=\"white\", markeredgecolor=\"black\")\n",
    "\n",
    "    # Plot boxplot\n",
    "    box_plot = sns.boxplot(\n",
    "        data=df[stage],\n",
    "        showmeans=True,\n",
    "        orient=\"h\",\n",
    "        linewidth=2,\n",
    "        flierprops=flierprops,\n",
    "        meanprops=meanprops,\n",
    "        palette=\"muted\",\n",
    "    )\n",
    "\n",
    "    box_plot.set(\n",
    "        xlabel=stage,\n",
    "        title=f\"Distribuição Total da Concentração de Todos os Metais no Estágio: {stage}\",\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando lista de cada estágio de cada minério\n",
    "\n",
    "feature_input = [\n",
    "    \"rougher.input.feed_au\",\n",
    "    \"rougher.input.feed_ag\",\n",
    "    \"rougher.input.feed_pb\",\n",
    "    \"rougher.input.feed_sol\",\n",
    "]\n",
    "\n",
    "feature_output = [\n",
    "    \"rougher.output.concentrate_au\",\n",
    "    \"rougher.output.concentrate_ag\",\n",
    "    \"rougher.output.concentrate_pb\",\n",
    "    \"rougher.output.concentrate_sol\",\n",
    "]\n",
    "\n",
    "feature_final = [\n",
    "    \"final.output.concentrate_au\",\n",
    "    \"final.output.concentrate_ag\",\n",
    "    \"final.output.concentrate_pb\",\n",
    "    \"final.output.concentrate_sol\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ROUGHER INPUT FEED STAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = calc_and_plot_total_concentrations(\n",
    "    df_full, \"feed_total_concentractions\", feature_input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ROUGHER OUTPUT STAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = calc_and_plot_total_concentrations(\n",
    "    df_full, \"rougher_output_total_concentractions\", feature_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **FINAL OUTPUT STAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = calc_and_plot_total_concentrations(\n",
    "    df_full, \"final_total_concentractions\", feature_final\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusão\n",
    "\n",
    "**ROUGHER INPUT FEED STAGE**\n",
    "\n",
    "- As concentrações totais de todas as substâncias no conjunto de origem são inclinadas à esquerda, pois o pico da distribuição está no lado direito e a média é menor que a mediana.\n",
    "\n",
    "- Existem muitos valores discrepantes, mas há um grande aumento incomum na concentração de todas as substâncias em 0.\n",
    "\n",
    "- Removeremos todas as observações no conjunto de origem - df_full onde df_full['feed_total_concentractions'] < 0,8\n",
    "\n",
    "\n",
    "**ROUGHER OUTPUT STAGE**\n",
    "\n",
    "- As concentrações totais de todas as substâncias no conjunto de origem são inclinadas à esquerda, pois o pico da distribuição está no lado direito e a média é menor que a mediana.\n",
    "\n",
    "- Existem muitos valores discrepantes, mas há um grande aumento incomum na concentração de todas as substâncias em 0.\n",
    "\n",
    "- Removeremos todas as observações no conjunto de origem - df_full onde df_full['rougher_output_total_concentractions'] < 0,8\n",
    "\n",
    "\n",
    "**FINAL OUTPUT STAGE**\n",
    "\n",
    "- As concentrações totais de todas as substâncias no conjunto de origem são inclinadas à esquerda, pois o pico da distribuição está no lado direito e a média é menor que a mediana.\n",
    "\n",
    "- Existem muitos valores discrepantes, mas há um grande aumento incomum na concentração de todas as substâncias em 0.\n",
    "\n",
    "- Removeremos todas as observações no conjunto de origem - df_full onde df_full['final_total_concentractions'] < 0,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2 Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ROUGHER INPUT FEED STAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = calc_and_plot_total_concentrations(\n",
    "    df_train, \"feed_total_concentractions\", feature_input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ROUGHER OUTPUT STAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = calc_and_plot_total_concentrations(\n",
    "    df_train, \"rougher_output_total_concentractions\", feature_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **FINAL OUTPUT STAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = calc_and_plot_total_concentrations(\n",
    "    df_train, \"final_total_concentractions\", feature_final\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusão\n",
    "\n",
    "**ROUGHER INPUT FEED STAGE**\n",
    "\n",
    "- As concentrações totais de todas as substâncias no conjunto de origem são inclinadas à esquerda, pois o pico da distribuição está no lado direito e a média é menor que a mediana.\n",
    "\n",
    "- Existem muitos valores discrepantes, mas há um grande aumento incomum na concentração de todas as substâncias em 0.\n",
    "\n",
    "- Removeremos todas as observações no conjunto de origem - df_train onde df_train['feed_total_concentractions'] < 0,8\n",
    "\n",
    "\n",
    "**ROUGHER OUTPUT STAGE**\n",
    "\n",
    "- As concentrações totais de todas as substâncias no conjunto de origem são inclinadas à esquerda, pois o pico da distribuição está no lado direito e a média é menor que a mediana.\n",
    "\n",
    "- Existem muitos valores discrepantes, mas há um grande aumento incomum na concentração de todas as substâncias em 0.\n",
    "\n",
    "- Removeremos todas as observações no conjunto de origem - df_train onde df_train['rougher_output_total_concentractions'] < 0,8\n",
    "\n",
    "\n",
    "**FINAL OUTPUT STAGE**\n",
    "\n",
    "- As concentrações totais de todas as substâncias no conjunto de origem são inclinadas à esquerda, pois o pico da distribuição está no lado direito e a média é menor que a mediana.\n",
    "\n",
    "- Existem muitos valores discrepantes, mas há um grande aumento incomum na concentração de todas as substâncias em 0.\n",
    "\n",
    "- Removeremos todas as observações no conjunto de origem - df_train onde df_train['final_total_concentractions'] < 0,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.3 Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o conjunto de dados de teste - df_test não possui todos os recursos de saída, temos apenas as colunas abaixo que vêm do estágio Raw Feed:\n",
    "\n",
    "- rougher.input.feed_ag\n",
    "- rougher.input.feed_pb\n",
    "- rougher.input.feed_sol\n",
    "- rougher.input.feed_au\n",
    "\n",
    "Podemos analisar as concentrações totais de todas as substâncias no conjunto de testes - df_test apenas para o estágio Raw Feed e encontrar e remover as anomalias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ROUGHER INPUT FEED STAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = calc_and_plot_total_concentrations(\n",
    "    df_test, \"feed_total_concentractions\", feature_input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusão\n",
    "\n",
    "**ROUGHER INPUT FEED STAGE**\n",
    "\n",
    "- As concentrações totais de todas as substâncias no conjunto de origem são inclinadas à esquerda, pois o pico da distribuição está no lado direito e a média é menor que a mediana.\n",
    "\n",
    "- Existem muitos valores discrepantes, mas há um grande aumento incomum na concentração de todas as substâncias em 0.\n",
    "\n",
    "- Removeremos todas as observações no conjunto de origem - df_test onde df_test['feed_total_concentractions'] < 0,8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.4 Removendo Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando os datasets com as conclusões encontradas anteriormente\n",
    "df_full = df_full[\n",
    "    (df_full[\"feed_total_concentractions\"] >= 0.8)\n",
    "    & (df_full[\"rougher_output_total_concentractions\"] >= 0.8)\n",
    "    & (df_full[\"final_total_concentractions\"] >= 0.8)\n",
    "]\n",
    "\n",
    "df_train = df_train[\n",
    "    (df_train[\"feed_total_concentractions\"] >= 0.8)\n",
    "    & (df_train[\"rougher_output_total_concentractions\"] >= 0.8)\n",
    "    & (df_train[\"final_total_concentractions\"] >= 0.8)\n",
    "]\n",
    "\n",
    "df_test = df_test[df_test[\"feed_total_concentractions\"] >= 0.8]\n",
    "\n",
    "# Obtendo o shape dos datasets filtrados\n",
    "df_full.shape, df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Preparando os Dados Finais para os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo cópias dos dataframes\n",
    "new_df_full = df_full.copy()\n",
    "new_df_train = df_train.copy()\n",
    "new_df_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as colunas criadas na seção anterior no dataframe new_df_train\n",
    "columns_to_drop = [\n",
    "    \"feed_total_concentractions\",\n",
    "    \"rougher_output_total_concentractions\",\n",
    "    \"final_total_concentractions\",\n",
    "]\n",
    "new_df_train = new_df_train.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# Removendo a coluna criada na seção anterior no dataframe new_df_test\n",
    "new_df_test = new_df_test.drop([\"feed_total_concentractions\"], axis=1)\n",
    "\n",
    "new_df_train.info(), new_df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos remover as colunas do dataset de treinamento que não estão presente no dataset de teste. Porém não podemos remover as 2 colunas objetivos, que são: \"rougher.output.recovery\" e \"final.output.recovery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando novamente as colunas faltantes no dataset df_test\n",
    "missed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo rougher.output.recovery e final.output.recovery da lista missed_columns\n",
    "missed_columns.remove(\"rougher.output.recovery\")\n",
    "missed_columns.remove(\"final.output.recovery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop colunas que não estão presentes no dataset df_test\n",
    "new_df_train = new_df_train.drop(missed_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando as colunas do new_df_train\n",
    "display(new_df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df_train shape\n",
    "new_df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, precisamos obter os valores das variáveis objetivo no conjunto de dados de origem (df_full)\n",
    "\n",
    "Temos dois alvos: rougher.output.recovery e final.output.recovery. \n",
    "\n",
    "Mas, no conjunto de testes (df_test) não possui nenhum deles, pois são colunas relacionadas à saída. Precisaremos de ambos os recursos para fins de validação.\n",
    "\n",
    "Sabemos que temos dados completos no conjunto de origem (df_full) e temos uma coluna em comum entre o conjunto de dados df_full e df_test, que é a coluna \"date\". Podemos usá-lo para mesclar os conjuntos de dados e recuperar os valores dos alvos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge new_df_full e new_df_test pela coluna \"date\"\n",
    "df_source_to_merge = new_df_full[\n",
    "    [\"date\", \"rougher.output.recovery\", \"final.output.recovery\"]\n",
    "]\n",
    "df_test_derived = pd.merge(df_source_to_merge, new_df_test, how=\"inner\", on=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_derived shape\n",
    "df_test_derived.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_derived info\n",
    "df_test_derived.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultima coisa a se fazer, é fazer o drop da coluna \"date\" do new_df_train e new_df_test, pois não são necessários para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date de  df_test_derived e new_df_train\n",
    "df_test_derived = df_test_derived.drop([\"date\"], axis=1)\n",
    "new_df_train = new_df_train.drop([\"date\"], axis=1)\n",
    "\n",
    "df_test_derived.columns, new_df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CONSTRUINDO O MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por conveniência e praticidade, vamos alterar os conjuntos de dados new_df_train e df_test_derived para df_train e df_test, respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renomeando os datasets\n",
    "df_train = new_df_train\n",
    "df_test = df_test_derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as features e target\n",
    "targets = [\"rougher.output.recovery\", \"final.output.recovery\"]\n",
    "\n",
    "features_train, target_train = df_train.drop(targets, axis=1), df_train[targets]\n",
    "features_test, target_test = df_test.drop(targets, axis=1), df_test[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features shape\n",
    "features_train.shape, features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets shape\n",
    "target_train.shape, target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer o preprocessamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando o StandardScale para padronizar os dados\n",
    "numeric_columns = features_train.select_dtypes(include=\"number\").columns.tolist()\n",
    "\n",
    "# Criar o pipeline com StandardScaler\n",
    "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "# Criar o pré-processador para as colunas numéricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"num\", numeric_transformer, numeric_columns)]\n",
    ")\n",
    "\n",
    "# Aplicar o pré-processador aos dados de treino e teste\n",
    "features_train_processed = preprocessor.fit_transform(features_train)\n",
    "features_test_processed = preprocessor.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Calculo final sMAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cálculo da função sMAPE:\n",
    "\n",
    "$$ sMAPE = {1 \\over N} \\sum_{i=1}^{N} {|y_i - \\hat y_i |\\over (|y_i| + |\\hat y_i|) / 2} * 100\\% $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para calcular smape\n",
    "def calculate_smape(real: pd.Series, prediction: pd.Series):\n",
    "    \"\"\"\n",
    "    Essa função:\n",
    "     1. Pega a série real de valores alvo para uma coluna e a série prevista de valores para essa coluna\n",
    "     2. Calcula o sMAPE\n",
    "     3. Retorna o sMAPE para coluna\n",
    "    \"\"\"\n",
    "\n",
    "    error = np.abs(real - prediction)\n",
    "    scale = (np.abs(real) + np.abs(prediction)) / 2\n",
    "    smape = (error / scale).mean() * 100\n",
    "\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cálculo da função Final sMAPE:\n",
    "\n",
    "$$sMAPE final = 25\\% * sMAPE(rougher) + 75\\% * sMAPE(final)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to final smape evaluation metric\n",
    "\n",
    "\n",
    "def calculate_final_smape(y_true_rougher, y_pred_rougher, y_true_final, y_pred_final):\n",
    "    \"\"\"\n",
    "    This function:\n",
    "    1. Pega os valores smapes das variáveis rougher.output.recovery & final.output.recovery\n",
    "    2. Calcula o final smape\n",
    "    3. Retorna o final smape\n",
    "    \"\"\"\n",
    "    smape_rougher = calculate_smape(y_true_rougher, y_pred_rougher)\n",
    "    smape_final = calculate_smape(y_true_final, y_pred_final)\n",
    "    final_smape = (0.25 * smape_rougher) + (0.75 * smape_final)\n",
    "\n",
    "    return final_smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar o score da função calculat_smape que foi definida acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_score = make_scorer(calculate_final_smape, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Treinando diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fit_score(model, params, name):\n",
    "    # Criar o objeto GridSearchCV\n",
    "    grid_search = GridSearchCV(model, params, scoring=smape_score, cv=5, verbose=0)\n",
    "\n",
    "    # Ajustar o modelo aos dados de treino\n",
    "    grid_search.fit(features_train, target_train)\n",
    "\n",
    "    # Fazer previsões nos dados de teste\n",
    "    predictions = grid_search.predict(features_test)\n",
    "\n",
    "    # Calcular métricas de avaliação\n",
    "    rmse = root_mean_squared_error(target_test, predictions)\n",
    "    mae = mean_absolute_error(target_test, predictions)\n",
    "\n",
    "    # Calcular o sMAPE para as colunas rougher.output.recovery e final.output.recovery\n",
    "    smape_rougher = calculate_smape(\n",
    "        target_test[\"rougher.output.recovery\"], predictions[:, 0]\n",
    "    )\n",
    "    smape_final = calculate_smape(\n",
    "        target_test[\"final.output.recovery\"], predictions[:, 1]\n",
    "    )\n",
    "\n",
    "    # Calcular o sMAPE final usando a função calculate_final_smape\n",
    "    final_smape = calculate_final_smape(\n",
    "        target_test[\"rougher.output.recovery\"],\n",
    "        predictions[:, 0],\n",
    "        target_test[\"final.output.recovery\"],\n",
    "        predictions[:, 1],\n",
    "    )\n",
    "\n",
    "    # Imprimir os melhores parâmetros encontrados pelo GridSearchCV\n",
    "    print(f\"Melhores Parâmetros para {name}:\", grid_search.best_params_)\n",
    "\n",
    "    # Imprimir as métricas de avaliação\n",
    "    print(f\"Root Mean Squared Error (RMSE) para {name}: {rmse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE) para {name}: {mae:.4f}\")\n",
    "\n",
    "    print(f\"sMAPE para rougher.output.recovery: {smape_rougher:.4f}\")\n",
    "    print(f\"sMAPE para final.output.recovery: {smape_final:.4f}\")\n",
    "    print(f\"Final sMAPE: {final_smape:.4f}\")\n",
    "\n",
    "    # Retornar as métricas\n",
    "    return rmse, mae, final_smape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Definir o modelo\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Definir a grade de hiperparâmetros para o GridSearchCV\n",
    "lr_params = {}\n",
    "\n",
    "# Chamar a função para treinar, ajustar e avaliar o modelo\n",
    "rmse_LR, mae_LR, final_smape_LR = train_fit_score(\n",
    "    lr_model, lr_params, \"Linear Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Definir o modelo\n",
    "dtr_model = DecisionTreeRegressor(random_state=12345)\n",
    "\n",
    "# Definir a grade de hiperparâmetros para o GridSearchCV\n",
    "dtr_params = {\"max_depth\": [None, 5, 10, 15, 20]}\n",
    "\n",
    "# Chamar a função para treinar, ajustar e avaliar o modelo\n",
    "rmse_DTR, mae_DTR, final_smape_DTR = train_fit_score(\n",
    "    dtr_model, dtr_params, \"Decision Tree Regressor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3 RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Definir o modelo\n",
    "rf_model = RandomForestRegressor(random_state=12345)\n",
    "\n",
    "# Definir a grade de hiperparâmetros para o GridSearchCV\n",
    "rf_params = {\n",
    "    \"n_estimators\": [10, 20],\n",
    "    \"max_depth\": [None, 5, 10, 15],\n",
    "}\n",
    "\n",
    "# Chamar a função para treinar, ajustar e avaliar o modelo\n",
    "rmse_RFR, mae_RFR, final_smape_RFR = train_fit_score(\n",
    "    rf_model, rf_params, \"Random Forest Regressor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CONCLUSÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um dicionário com os resultados\n",
    "results = {\n",
    "    \"Model\": [\n",
    "        \"Linear Regression\",\n",
    "        \"Decision Tree Regressor\",\n",
    "        \"Random Forest Regressor\",\n",
    "    ],\n",
    "    \"RMSE\": [rmse_LR, rmse_DTR, rmse_RFR],\n",
    "    \"MAE\": [mae_LR, mae_DTR, mae_RFR],\n",
    "    \"Final sMAPE\": [final_smape_LR, final_smape_DTR, final_smape_RFR],\n",
    "}\n",
    "\n",
    "# Criar um DataFrame a partir do dicionário\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Imprimir a tabela\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vamos interpretar os resultados das métricas para cada modelo:\n",
    "\n",
    "1. Linear Regression:\n",
    "\n",
    "- RMSE (Root Mean Squared Error): 6.734879\n",
    "- MAE (Mean Absolute Error): 4.844372\n",
    "- Final sMAPE: 7.584517\n",
    "\n",
    "O modelo de Regressão Linear apresenta um desempenho relativamente bom, com valores baixos de RMSE e MAE, indicando que as previsões estão próximas dos valores reais. O valor do Final sMAPE também é baixo, sugerindo que o modelo tem uma boa capacidade de previsão.\n",
    "\n",
    "2. Decision Tree Regressor:\n",
    "\n",
    "- RMSE: 10.966146\n",
    "- MAE: 8.036983\n",
    "- Final sMAPE: 13.920446\n",
    "\n",
    "O Decision Tree Regressor apresenta valores mais altos de RMSE, MAE e Final sMAPE em comparação com a Regressão Linear. Isso indica que o modelo de árvore de decisão tem um desempenho inferior na previsão dos dados em comparação com a Regressão Linear.\n",
    "\n",
    "3. Random Forest Regressor:\n",
    "\n",
    "- RMSE: 6.811704\n",
    "- MAE: 5.108131\n",
    "- Final sMAPE: 8.072978\n",
    "\n",
    "O Random Forest Regressor apresenta métricas semelhantes à Regressão Linear, indicando um desempenho sólido. O RMSE e o MAE são baixos, sugerindo previsões precisas, e o Final sMAPE também é baixo, indicando uma boa capacidade de generalização.\n",
    "\n",
    "Conclusões:\n",
    "\n",
    "- A Regressão Linear e o Random Forest Regressor mostraram desempenhos comparativamente bons.\n",
    "\n",
    "- O Decision Tree Regressor teve um desempenho inferior em comparação com os outros dois modelos, com valores mais altos de todas as métricas.\n",
    "\n",
    "- Ao considerar o Final sMAPE, que combina as métricas para ambas as saídas (\"rougher.output.recovery\" e \"final.output.recovery\"), o Linear Regression parece ser uma escolha mais sólida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
